{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flydragon2018/colab_notebooks/blob/main/colab_pytorch_arcface_gempooling_tpu_train_b6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85cb311d"
      },
      "source": [
        "<br>\n",
        "<h2 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">[Pytorch] ArcFace Starter</h2>\n",
        "<br>"
      ],
      "id": "85cb311d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f011333"
      },
      "source": [
        "<br>\n",
        "\n",
        "It is based on the work of VLAD VADUVA https://www.kaggle.com/vladvdv/pytorch-train-notebook-arcface-gem-pooling\n",
        "\n",
        "### I can't use wandb with tpu. If you know how to use it with tpu, please comment!\n",
        "\n",
        "* v1: quick save\n",
        "* v2: add code for tpu with huggingface accelerate\n",
        "* v3: trying to fix error ...\n",
        "* v4: quick save\n",
        "* v5: trying to fix error ..."
      ],
      "id": "5f011333"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fac12c4e"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Install Required Libraries</h1></span>"
      ],
      "id": "fac12c4e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU1WOsqnAM7o",
        "outputId": "b05cbbcf-bd69-45bc-c978-b32259729b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mydrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive', force_remount=True)"
      ],
      "id": "rU1WOsqnAM7o"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x533vKS1ANAV"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "x533vKS1ANAV"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d41e77c5",
        "outputId": "0f4a10b9-84a7-47a3-fb02-bf61d5ac8b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  30819      0 --:--:-- --:--:-- --:--:-- 30634\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.8.1 ...\n",
            "Found existing installation: torch 1.8.0a0+56b43f4\n",
            "Uninstalling torch-1.8.0a0+56b43f4:\n",
            "  Successfully uninstalled torch-1.8.0a0+56b43f4\n",
            "Found existing installation: torchvision 0.10.0a0+3926c90\n",
            "Uninstalling torchvision-0.10.0a0+3926c90:\n",
            "  Successfully uninstalled torchvision-0.10.0a0+3926c90\n",
            "Copying gs://tpu-pytorch/wheels/torch-1.8.1-cp37-cp37m-linux_x86_64.whl...\n",
            "| [1 files][126.5 MiB/126.5 MiB]                                                \n",
            "Operation completed over 1 objects/126.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl...\n",
            "Done updating TPU runtime\n",
            "| [1 files][138.2 MiB/138.2 MiB]                                                \n",
            "Operation completed over 1 objects/138.2 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-1.8.1-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  5.1 MiB/  5.1 MiB]                                                \n",
            "Operation completed over 1 objects/5.1 MiB.                                      \n",
            "Processing ./torch-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 0.5.4 requires torchvision, which is not installed.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0a0+56b43f4 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0a0+56b43f4 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0a0+56b43f4\n",
            "Processing ./torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
            "torch-xla is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "Processing ./torchvision-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==1.8.1) (1.8.0a0+56b43f4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==1.8.1) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==1.8.1) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==1.8.1) (3.10.0.2)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.10.0a0+3926c90\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version 1.8.1 --apt-packages libomp5 libopenblas-dev"
      ],
      "id": "d41e77c5"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c9aa9388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e663ebb7-6c36-4d36-b605-b0a60c7f5dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0a0+3926c90)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.8.0a0+56b43f4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.10)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.6)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.8.0a0+56b43f4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install --upgrade wandb\n",
        "!pip install accelerate"
      ],
      "id": "c9aa9388"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57fcfdd4"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Required Libraries 📚</h1></span>"
      ],
      "id": "57fcfdd4"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w_YaPKkxCZv_"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU albumentations==0.4.6"
      ],
      "id": "w_YaPKkxCZv_"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "doiwDla1CZ0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c3f36b-2664-4c71-8b39-10435a024380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.2.52\n",
            "Uninstalling opencv-python-headless-4.5.2.52:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.2.52.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-8daa01ff.so.58.109.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-06a336f2.so.58.61.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-01d48d95.so.56.60.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-098682aa.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-c2ffaf3d.so.15.13.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-f3db6a3b.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-4767dc06.so.3.8.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-2d2bce5d.so.5.8.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-14094576.so.6.3.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libz-d8a329de.so.1.2.7\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.5.2.52\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62"
      ],
      "id": "doiwDla1CZ0g"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XFYr-ho9HG_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07485ac2-4e23-40be-d8d6-7aae9597c188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Using cached opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "id": "XFYr-ho9HG_m"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhAMC-muHHDl",
        "outputId": "251157e5-d7ab-4753-dafb-beff224ad2d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "id": "mhAMC-muHHDl"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_ZPbVfAKExU",
        "outputId": "2733b689-0b4e-41bb-8433-1db9b5e4cefb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install colorama"
      ],
      "id": "k_ZPbVfAKExU"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f966c1cf",
        "outputId": "d324ee1f-c1f5-4f09-afec-ad57a7747515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# For Image Models\n",
        "import timm\n",
        "\n",
        "# Albumentations for augmentations\n",
        "\n",
        "#from albumentations.pytorch import ToTensorV2\n",
        "import albumentations  as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "b_ = Fore.BLUE\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "# For TPU Training\n",
        "from accelerate import Accelerator, notebook_launcher\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "id": "f966c1cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba12a6e0"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\"> Weights & Biases (W&B) is a set of machine learning tools that helps you build better models faster. <strong>Kaggle competitions require fast-paced model development and evaluation</strong>. There are a lot of components: exploring the training data, training different models, combining trained models in different combinations (ensembling), and so on.</span>\n",
        "\n",
        "> <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">⏳ Lots of components = Lots of places to go wrong = Lots of time spent debugging</span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">W&B can be useful for Kaggle competition with it's lightweight and interoperable tools:</span>\n",
        "\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Quickly track experiments,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Version and iterate on datasets, <br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Evaluate model performance,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Reproduce models,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Visualize results and spot regressions,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Share findings with colleagues.</span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">To learn more about Weights and Biases check out this <strong><a href=\"https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases\">kernel</a></strong>.</span>"
      ],
      "id": "ba12a6e0"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "a245f610",
        "outputId": "7d454bcd-5d36-49bb-c6b3-0021c6cf3f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport wandb\\n\\ntry:\\n    from kaggle_secrets import UserSecretsClient\\n    user_secrets = UserSecretsClient()\\n    api_key = user_secrets.get_secret(\"wandb_api\")\\n    wandb.login(key=api_key)\\n    anony = None\\nexcept:\\n    anony = \"must\"\\n    print(\\'If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize\\')\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "'''\n",
        "import wandb\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
        "    wandb.login(key=api_key)\n",
        "    anony = None\n",
        "except:\n",
        "    anony = \"must\"\n",
        "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
        "\n",
        "'''"
      ],
      "id": "a245f610"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b411de57"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Configuration ⚙️</h1></span>"
      ],
      "id": "b411de57"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8e191d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "81134657-eba1-4ec7-fc81-de2b12f97ea1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nCONFIG = {\"seed\": 2022,\\n          \"epochs\": 50,\\n          \"img_size\": 768,\\n          \"model_name\": \"tf_efficientnet_b4\",\\n          \"num_classes\": 15587,\\n          \"train_batch_size\": 8,\\n          \"valid_batch_size\": 8,\\n          \"learning_rate\": 0.0001,\\n          \"scheduler\": \\'OneCycleLR\\',\\n          \"min_lr\": 1e-6,\\n          \"T_max\": 500,\\n          \"weight_decay\": 1e-6,\\n          \"n_fold\": 5,\\n          \"fold_to_run\": 0,\\n          \"n_accumulate\": 1,\\n          \"test_mode\":True, # enable for testing pipeline, changes epochs to 2 and uses just 200 training samples\\n          \"log_freq\": 20,\\n          # ArcFace Hyperparameters\\n          \"s\": 30.0, \\n          \"m\": 0.30,\\n          \"ls_eps\": 0.0,\\n          \"easy_margin\": False\\n          }\\n  '"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "'''\n",
        "CONFIG = {\"seed\": 2022,\n",
        "          \"epochs\": 50,\n",
        "          \"img_size\": 768,\n",
        "          \"model_name\": \"tf_efficientnet_b4\",\n",
        "          \"num_classes\": 15587,\n",
        "          \"train_batch_size\": 8,\n",
        "          \"valid_batch_size\": 8,\n",
        "          \"learning_rate\": 0.0001,\n",
        "          \"scheduler\": 'OneCycleLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"fold_to_run\": 0,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"test_mode\":True, # enable for testing pipeline, changes epochs to 2 and uses just 200 training samples\n",
        "          \"log_freq\": 20,\n",
        "          # ArcFace Hyperparameters\n",
        "          \"s\": 30.0, \n",
        "          \"m\": 0.30,\n",
        "          \"ls_eps\": 0.0,\n",
        "          \"easy_margin\": False\n",
        "          }\n",
        "  '''"
      ],
      "id": "8e191d55"
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\"seed\": 2022,\n",
        "          \"epochs\": 50,\n",
        "          \"img_size\": 768,\n",
        "          \"model_name\": \"tf_efficientnet_b6\",\n",
        "          \"num_classes\": 15587,\n",
        "          \"train_batch_size\": 8,\n",
        "          \"valid_batch_size\": 8,\n",
        "          \"learning_rate\": 0.001,\n",
        "          \"scheduler\": 'OneCycleLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"fold_to_run\": 0,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"test_mode\":False, # enable for testing pipeline, changes epochs to 2 and uses just 200 training samples\n",
        "          \"log_freq\": 20,\n",
        "          # ArcFace Hyperparameters\n",
        "          \"s\": 30.0, \n",
        "          \"m\": 0.30,\n",
        "          \"ls_eps\": 0.0,\n",
        "          \"easy_margin\": False\n",
        "          }\n"
      ],
      "metadata": {
        "id": "WWBJw-DQMJ19"
      },
      "id": "WWBJw-DQMJ19",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c172e12"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1></span>"
      ],
      "id": "7c172e12"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4621fb38"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed(CONFIG['seed'])"
      ],
      "id": "4621fb38"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ba760d4f"
      },
      "outputs": [],
      "source": [
        "\n",
        "TRAIN_DIR = '/content/mydrive/MyDrive/kaggle/train_images-384-384/train_images-384-384'\n",
        "TEST_DIR = '/content/mydrive/MyDrive/kaggle/test_images-384-384/test_images-384-384'"
      ],
      "id": "ba760d4f"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "816e9c58"
      },
      "outputs": [],
      "source": [
        "def get_train_file_path(id):\n",
        "    return f\"{TRAIN_DIR}/{id}\""
      ],
      "id": "816e9c58"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb907b26"
      },
      "source": [
        "# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Read the Data 📖</h1>"
      ],
      "id": "fb907b26"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "50a04495"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"/content/mydrive/MyDrive/kaggle/HappyWhale-2022/train.csv\")\n",
        "df['file_path'] = df['image'].apply(get_train_file_path)\n",
        "df.head()\n",
        "\n",
        "\n",
        "CONFIG[\"test_mode\"]=False\n",
        "if CONFIG[\"test_mode\"]==True:\n",
        "    df=df[:200]\n",
        "    CONFIG[\"epochs\"] = 2\n",
        "    CONFIG[\"n_fold\"] = 3\n",
        "encoder = LabelEncoder()\n",
        "df['individual_id'] = encoder.fit_transform(df['individual_id'])\n",
        "\n",
        "with open(\"le.pkl\", \"wb\") as fp:\n",
        "    joblib.dump(encoder, fp)"
      ],
      "id": "50a04495"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4388dc7"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Folds</h1></span>"
      ],
      "id": "d4388dc7"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "641276b4"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n",
        "\n",
        "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.individual_id)):\n",
        "      df.loc[val_ , \"kfold\"] = fold"
      ],
      "id": "641276b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9d1b63"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Dataset Class</h1></span>"
      ],
      "id": "1b9d1b63"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "c263eabe"
      },
      "outputs": [],
      "source": [
        "class HappyWhaleDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.file_names = df['file_path'].values\n",
        "        self.labels = df['individual_id'].values\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_names[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "            \n",
        "        return {\n",
        "            'image': img,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "id": "c263eabe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81f8e01b"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h1></span>"
      ],
      "id": "81f8e01b"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4b20e02f"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], \n",
        "                std=[0.229, 0.224, 0.225], \n",
        "                max_pixel_value=255.0, \n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.),\n",
        "    \n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], \n",
        "                std=[0.229, 0.224, 0.225], \n",
        "                max_pixel_value=255.0, \n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.)\n",
        "}"
      ],
      "id": "4b20e02f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0422774"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">GeM Pooling</h1></span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://amaarora.github.io/2020/08/30/gempool.html\">GeM Pooling Explained</a></span>\n",
        "\n",
        "![](https://i.imgur.com/thTgYWG.jpg)"
      ],
      "id": "e0422774"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3c4a6f51"
      },
      "outputs": [],
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1)*p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)\n",
        "        \n",
        "    def gem(self, x, p=3, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \\\n",
        "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
        "                ', ' + 'eps=' + str(self.eps) + ')'"
      ],
      "id": "3c4a6f51"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ade83e6"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">ArcFace</h1></span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\">Landmark2019-1st-and-3rd-Place-Solution</a></span>"
      ],
      "id": "9ade83e6"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1a180beb"
      },
      "outputs": [],
      "source": [
        "class ArcMarginProduct(nn.Module):\n",
        "    r\"\"\"Implement of large margin arc distance: :\n",
        "        Args:\n",
        "            in_features: size of each input sample\n",
        "            out_features: size of each output sample\n",
        "            s: norm of input feature\n",
        "            m: margin\n",
        "            cos(theta + m)\n",
        "        \"\"\"\n",
        "    def __init__(self, in_features, out_features, accelerator,s=30.0, \n",
        "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
        "        super(ArcMarginProduct, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps  # label smoothing\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "        self.accelerator = accelerator\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        # --------------------------- convert label to one-hot ---------------------\n",
        "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
        "        one_hot = torch.zeros(cosine.size(), device=self.accelerator.device)\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
        "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "\n",
        "        return output"
      ],
      "id": "1a180beb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d00280b1"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Model</h1></span>"
      ],
      "id": "d00280b1"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "046180c0"
      },
      "outputs": [],
      "source": [
        "class HappyWhaleModel(nn.Module):\n",
        "    def __init__(self, model_name, accelerator,pretrained=True):\n",
        "        super(HappyWhaleModel, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        in_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Identity()\n",
        "        self.model.global_pool = nn.Identity()\n",
        "        self.pooling = GeM()\n",
        "        self.drop = nn.Dropout(p=0.2, inplace=False)\n",
        "        self.fc = nn.Linear(in_features,512)\n",
        "        self.arc = ArcMarginProduct(512, \n",
        "                           CONFIG[\"num_classes\"],\n",
        "                            accelerator,\n",
        "                           s=CONFIG[\"s\"], \n",
        "                           m=CONFIG[\"m\"], \n",
        "                           easy_margin=CONFIG[\"ls_eps\"], \n",
        "                           ls_eps=CONFIG[\"ls_eps\"])\n",
        "    def forward(self, images, labels):\n",
        "        features = self.model(images)\n",
        "        pooled_features = self.pooling(features).flatten(1)\n",
        "        pooled_drop = self.drop(pooled_features)\n",
        "        emb = self.fc(pooled_drop)\n",
        "        output = self.arc(emb,labels)\n",
        "        return output,emb\n"
      ],
      "id": "046180c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d9f236f"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h1></span>"
      ],
      "id": "1d9f236f"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f21a2952"
      },
      "outputs": [],
      "source": [
        "def criterion(outputs, labels):\n",
        "    return nn.CrossEntropyLoss()(outputs, labels)"
      ],
      "id": "f21a2952"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eb206fc"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h1></span>"
      ],
      "id": "2eb206fc"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1b479ae1"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, accelerator, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for step, data in enumerate(dataloader):\n",
        "        images = data['image']\n",
        "        labels = data['label']\n",
        "        \n",
        "        batch_size = images.size(0)\n",
        "        \n",
        "        outputs, emb = model(images, labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss = loss / CONFIG['n_accumulate']\n",
        "       \n",
        "        accelerator.backward(loss)\n",
        "    \n",
        "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
        "            optimizer.step()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                \n",
        "        \n",
        "        if step % CONFIG['log_freq'] == 0:\n",
        "            running_loss += (loss.item() * batch_size)\n",
        "            dataset_size += batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        \n",
        "        del images, labels, batch_size, outputs, emb, loss\n",
        "        gc.collect()\n",
        "        \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ],
      "id": "1b479ae1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6379e683"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1></span>"
      ],
      "id": "6379e683"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a181de1a"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model,optimizer, dataloader, accelerator, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for step, data in enumerate(dataloader):        \n",
        "        images = data['image']\n",
        "        labels = data['label']\n",
        "        \n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        outputs, emb = model(images, labels)\n",
        "        \n",
        "        all_outputs = accelerator.gather(outputs)\n",
        "        all_labels = accelerator.gather(labels)\n",
        "        loss = criterion(all_outputs, all_labels)\n",
        "        \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        del images, labels, batch_size, outputs, emb, all_outputs, all_labels, loss\n",
        "        gc.collect()\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ],
      "id": "a181de1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6f82412"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h1></span>"
      ],
      "id": "a6f82412"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "db043394"
      },
      "outputs": [],
      "source": [
        "def run_training(num_epochs):\n",
        "    accelerator = Accelerator()\n",
        "    \n",
        "    model = HappyWhaleModel(CONFIG['model_name'], accelerator)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n",
        "                       weight_decay=CONFIG['weight_decay'])\n",
        "    \n",
        "    train_loader, valid_loader = prepare_loaders(df, fold=CONFIG['fold_to_run'])\n",
        "    \n",
        "    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader)\n",
        "    valid_loader = accelerator.prepare(valid_loader)\n",
        "    \n",
        "    scheduler = fetch_scheduler(optimizer, train_loader)\n",
        "    \n",
        "#     run = wandb.init(project='happywhale', \n",
        "#                  config=CONFIG,\n",
        "#                  job_type='Train',\n",
        "#                  tags=['arcface', 'gem-pooling', 'effnet-b4', '768'],\n",
        "#                  anonymous='must',\n",
        "#                 group='DDP')\n",
        "\n",
        "#    # To automatically log gradients\n",
        "#    wandb.watch(model, log_freq=100)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "    \n",
        "    start = time.time()\n",
        "    best_epoch_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1): \n",
        "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           accelerator=accelerator, epoch=epoch)\n",
        "        \n",
        "        val_epoch_loss = valid_one_epoch(model,optimizer, valid_loader, accelerator=accelerator, \n",
        "                                         epoch=epoch)\n",
        "        \n",
        "        \n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "\n",
        " #       # Log the metrics\n",
        " #       wandb.log({\"Train Loss\": train_epoch_loss})\n",
        " #       wandb.log({\"Valid Loss\": val_epoch_loss})\n",
        " #       wandb.log({\"LR\": optimizer.param_groups[0]['lr']})\n",
        "            \n",
        "        # save model\n",
        "        accelerator.print(f\"{b_}Validation Loss: {val_epoch_loss}\")\n",
        "        best_epoch_loss = val_epoch_loss\n",
        "#                 run.summary[\"Best Loss\"] = best_epoch_loss\n",
        "        PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n",
        "        accelerator.wait_for_everyone()\n",
        "        unwrapped_model = accelerator.unwrap_model(model)\n",
        "        accelerator.save(unwrapped_model.state_dict(), PATH)\n",
        "        # Save a model file from the current directory\n",
        "        accelerator.print(f\"Model Saved{sr_}\")\n",
        "        \n",
        "        del train_epoch_loss, val_epoch_loss\n",
        "        gc.collect()\n",
        "            \n",
        "        accelerator.print()\n",
        "    \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    accelerator.print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    accelerator.print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
        "#     run.finish()"
      ],
      "id": "db043394"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "08f53240"
      },
      "outputs": [],
      "source": [
        "def fetch_scheduler(optimizer, train_loader):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
        "                                                   eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
        "                                                             eta_min=CONFIG['min_lr'])\n",
        "                \n",
        "    elif CONFIG['scheduler'] == 'OneCycleLR':\n",
        "        scheduler = lr_scheduler.OneCycleLR(optimizer,max_lr =CONFIG['learning_rate'],total_steps = CONFIG['epochs'] * len(train_loader))\n",
        "        \n",
        "    elif CONFIG['scheduler'] == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler"
      ],
      "id": "08f53240"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "e680b3c8"
      },
      "outputs": [],
      "source": [
        "def prepare_loaders(df, fold):\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"])\n",
        "    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
        "                              num_workers=1, shuffle=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=1, shuffle=False)\n",
        "    \n",
        "    return train_loader, valid_loader"
      ],
      "id": "e680b3c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31b1e58e"
      },
      "source": [
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>"
      ],
      "id": "31b1e58e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "390f5279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8d10ac-780f-4df6-f0ad-ee69dfddb50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching a training on 8 TPU cores.\n"
          ]
        }
      ],
      "source": [
        "def launch():\n",
        "    #run_training(num_epochs=CONFIG['epochs'])\n",
        "    run_training(num_epochs=CONFIG['epochs'])\n",
        "    \n",
        "notebook_launcher(launch)"
      ],
      "id": "390f5279"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wv2v2Y3NrOF"
      },
      "outputs": [],
      "source": [
        "!cp /content/*.bin /content/mydrive/MyDrive/kaggle/pytorch_arcface_bin_pkl/"
      ],
      "id": "9wv2v2Y3NrOF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF0PEeJtLvD-"
      },
      "outputs": [],
      "source": [
        "!cp /content/*.pkl /content/mydrive/MyDrive/kaggle/pytorch_arcface_bin_pkl/"
      ],
      "id": "BF0PEeJtLvD-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEwchhv5LvLA"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "zEwchhv5LvLA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baaf8ade"
      },
      "source": [
        "# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualizations</h1>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https://wandb.ai/dchanda/HappyWhale/runs/3j25um1k\">View the Complete Dashboard Here ⮕</a></span>"
      ],
      "id": "baaf8ade"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eeb0bd7"
      },
      "source": [
        "![](https://i.imgur.com/zD3rD0W.jpg)"
      ],
      "id": "0eeb0bd7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70118c85"
      },
      "source": [
        "![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)"
      ],
      "id": "70118c85"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "colab pytorch-arcface-gempooling-tpu-train-b6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 374.081758,
      "end_time": "2022-02-25T04:32:01.816711",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-02-25T04:25:47.734953",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}