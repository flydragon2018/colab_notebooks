{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flydragon2018/colab_notebooks/blob/main/colab_pytorch_arcface_gempooling_tpu_train_b6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85cb311d"
      },
      "source": [
        "<br>\n",
        "<h2 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">[Pytorch] ArcFace Starter</h2>\n",
        "<br>"
      ],
      "id": "85cb311d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f011333"
      },
      "source": [
        "<br>\n",
        "\n",
        "It is based on the work of VLAD VADUVA https://www.kaggle.com/vladvdv/pytorch-train-notebook-arcface-gem-pooling\n",
        "\n",
        "### I can't use wandb with tpu. If you know how to use it with tpu, please comment!\n",
        "\n",
        "* v1: quick save\n",
        "* v2: add code for tpu with huggingface accelerate\n",
        "* v3: trying to fix error ...\n",
        "* v4: quick save\n",
        "* v5: trying to fix error ..."
      ],
      "id": "5f011333"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fac12c4e"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Install Required Libraries</h1></span>"
      ],
      "id": "fac12c4e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU1WOsqnAM7o",
        "outputId": "59746138-5d3d-4a26-9bc4-ffa8df75af10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mydrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive', force_remount=True)"
      ],
      "id": "rU1WOsqnAM7o"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x533vKS1ANAV"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "x533vKS1ANAV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d41e77c5",
        "outputId": "b4d8bbdd-0bf2-4c1a-d487-fa5f13a854ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5116  100  5116    0     0  39353      0 --:--:-- --:--:-- --:--:-- 39353\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.8.1 ...\n",
            "Found existing installation: torch 1.10.0+cu111\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.35.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.54.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Uninstalling torch-1.10.0+cu111:\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.10\n",
            "    Uninstalling google-api-python-client-1.12.10:\n",
            "      Successfully uninstalled google-api-python-client-1.12.10\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.299 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.10.0+cu111\n",
            "Found existing installation: torchvision 0.11.1+cu111\n",
            "Uninstalling torchvision-0.11.1+cu111:\n",
            "  Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Copying gs://tpu-pytorch/wheels/torch-1.8.1-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][126.5 MiB/126.5 MiB]                                                \n",
            "Operation completed over 1 objects/126.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][138.2 MiB/138.2 MiB]                                                \n",
            "Operation completed over 1 objects/138.2 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-1.8.1-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  5.1 MiB/  5.1 MiB]                                                \n",
            "Operation completed over 1 objects/5.1 MiB.                                      \n",
            "Processing ./torch-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version 1.8.1 --apt-packages libomp5 libopenblas-dev"
      ],
      "id": "d41e77c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9aa9388"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!pip install --upgrade wandb\n",
        "!pip install accelerate"
      ],
      "id": "c9aa9388"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57fcfdd4"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Required Libraries 📚</h1></span>"
      ],
      "id": "57fcfdd4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_YaPKkxCZv_"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU albumentations==0.4.6"
      ],
      "id": "w_YaPKkxCZv_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doiwDla1CZ0g"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall opencv-python-headless==4.5.5.62"
      ],
      "id": "doiwDla1CZ0g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFYr-ho9HG_m"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "id": "XFYr-ho9HG_m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhAMC-muHHDl"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "id": "mhAMC-muHHDl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZPbVfAKExU"
      },
      "outputs": [],
      "source": [
        "!pip install colorama"
      ],
      "id": "k_ZPbVfAKExU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f966c1cf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm.auto import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# For Image Models\n",
        "import timm\n",
        "\n",
        "# Albumentations for augmentations\n",
        "\n",
        "#from albumentations.pytorch import ToTensorV2\n",
        "import albumentations  as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "b_ = Fore.BLUE\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "# For TPU Training\n",
        "from accelerate import Accelerator, notebook_launcher\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "id": "f966c1cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba12a6e0"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\"> Weights & Biases (W&B) is a set of machine learning tools that helps you build better models faster. <strong>Kaggle competitions require fast-paced model development and evaluation</strong>. There are a lot of components: exploring the training data, training different models, combining trained models in different combinations (ensembling), and so on.</span>\n",
        "\n",
        "> <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">⏳ Lots of components = Lots of places to go wrong = Lots of time spent debugging</span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">W&B can be useful for Kaggle competition with it's lightweight and interoperable tools:</span>\n",
        "\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Quickly track experiments,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Version and iterate on datasets, <br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Evaluate model performance,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Reproduce models,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Visualize results and spot regressions,<br></span>\n",
        "* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Share findings with colleagues.</span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">To learn more about Weights and Biases check out this <strong><a href=\"https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases\">kernel</a></strong>.</span>"
      ],
      "id": "ba12a6e0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a245f610"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import wandb\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    api_key = user_secrets.get_secret(\"wandb_api\")\n",
        "    wandb.login(key=api_key)\n",
        "    anony = None\n",
        "except:\n",
        "    anony = \"must\"\n",
        "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
        "\n",
        "'''"
      ],
      "id": "a245f610"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b411de57"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Configuration ⚙️</h1></span>"
      ],
      "id": "b411de57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e191d55"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "CONFIG = {\"seed\": 2022,\n",
        "          \"epochs\": 50,\n",
        "          \"img_size\": 768,\n",
        "          \"model_name\": \"tf_efficientnet_b4\",\n",
        "          \"num_classes\": 15587,\n",
        "          \"train_batch_size\": 8,\n",
        "          \"valid_batch_size\": 8,\n",
        "          \"learning_rate\": 0.0001,\n",
        "          \"scheduler\": 'OneCycleLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"fold_to_run\": 0,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"test_mode\":True, # enable for testing pipeline, changes epochs to 2 and uses just 200 training samples\n",
        "          \"log_freq\": 20,\n",
        "          # ArcFace Hyperparameters\n",
        "          \"s\": 30.0, \n",
        "          \"m\": 0.30,\n",
        "          \"ls_eps\": 0.0,\n",
        "          \"easy_margin\": False\n",
        "          }\n",
        "  '''"
      ],
      "id": "8e191d55"
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\"seed\": 2022,\n",
        "          \"epochs\": 50,\n",
        "          \"img_size\": 768,\n",
        "          \"model_name\": \"tf_efficientnet_b6\",\n",
        "          \"num_classes\": 15587,\n",
        "          \"train_batch_size\": 8,\n",
        "          \"valid_batch_size\": 8,\n",
        "          \"learning_rate\": 0.001,\n",
        "          \"scheduler\": 'OneCycleLR',\n",
        "          \"min_lr\": 1e-6,\n",
        "          \"T_max\": 500,\n",
        "          \"weight_decay\": 1e-6,\n",
        "          \"n_fold\": 5,\n",
        "          \"fold_to_run\": 0,\n",
        "          \"n_accumulate\": 1,\n",
        "          \"test_mode\":False, # enable for testing pipeline, changes epochs to 2 and uses just 200 training samples\n",
        "          \"log_freq\": 20,\n",
        "          # ArcFace Hyperparameters\n",
        "          \"s\": 30.0, \n",
        "          \"m\": 0.30,\n",
        "          \"ls_eps\": 0.0,\n",
        "          \"easy_margin\": False\n",
        "          }\n"
      ],
      "metadata": {
        "id": "WWBJw-DQMJ19"
      },
      "id": "WWBJw-DQMJ19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c172e12"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1></span>"
      ],
      "id": "7c172e12"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4621fb38"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed(CONFIG['seed'])"
      ],
      "id": "4621fb38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba760d4f"
      },
      "outputs": [],
      "source": [
        "\n",
        "TRAIN_DIR = '/content/mydrive/MyDrive/kaggle/train_images-384-384/train_images-384-384'\n",
        "TEST_DIR = '/content/mydrive/MyDrive/kaggle/test_images-384-384/test_images-384-384'"
      ],
      "id": "ba760d4f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "816e9c58"
      },
      "outputs": [],
      "source": [
        "def get_train_file_path(id):\n",
        "    return f\"{TRAIN_DIR}/{id}\""
      ],
      "id": "816e9c58"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb907b26"
      },
      "source": [
        "# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Read the Data 📖</h1>"
      ],
      "id": "fb907b26"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50a04495"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"/content/mydrive/MyDrive/kaggle/HappyWhale-2022/train.csv\")\n",
        "df['file_path'] = df['image'].apply(get_train_file_path)\n",
        "df.head()\n",
        "\n",
        "\n",
        "CONFIG[\"test_mode\"]=False\n",
        "if CONFIG[\"test_mode\"]==True:\n",
        "    df=df[:200]\n",
        "    CONFIG[\"epochs\"] = 2\n",
        "    CONFIG[\"n_fold\"] = 3\n",
        "encoder = LabelEncoder()\n",
        "df['individual_id'] = encoder.fit_transform(df['individual_id'])\n",
        "\n",
        "with open(\"le.pkl\", \"wb\") as fp:\n",
        "    joblib.dump(encoder, fp)"
      ],
      "id": "50a04495"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4388dc7"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Folds</h1></span>"
      ],
      "id": "d4388dc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "641276b4"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n",
        "\n",
        "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.individual_id)):\n",
        "      df.loc[val_ , \"kfold\"] = fold"
      ],
      "id": "641276b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9d1b63"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Dataset Class</h1></span>"
      ],
      "id": "1b9d1b63"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c263eabe"
      },
      "outputs": [],
      "source": [
        "class HappyWhaleDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.file_names = df['file_path'].values\n",
        "        self.labels = df['individual_id'].values\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_names[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        label = self.labels[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "            \n",
        "        return {\n",
        "            'image': img,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "id": "c263eabe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81f8e01b"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h1></span>"
      ],
      "id": "81f8e01b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b20e02f"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], \n",
        "                std=[0.229, 0.224, 0.225], \n",
        "                max_pixel_value=255.0, \n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.),\n",
        "    \n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], \n",
        "                std=[0.229, 0.224, 0.225], \n",
        "                max_pixel_value=255.0, \n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.)\n",
        "}"
      ],
      "id": "4b20e02f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0422774"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">GeM Pooling</h1></span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://amaarora.github.io/2020/08/30/gempool.html\">GeM Pooling Explained</a></span>\n",
        "\n",
        "![](https://i.imgur.com/thTgYWG.jpg)"
      ],
      "id": "e0422774"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c4a6f51"
      },
      "outputs": [],
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1)*p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)\n",
        "        \n",
        "    def gem(self, x, p=3, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \\\n",
        "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
        "                ', ' + 'eps=' + str(self.eps) + ')'"
      ],
      "id": "3c4a6f51"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ade83e6"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">ArcFace</h1></span>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\">Landmark2019-1st-and-3rd-Place-Solution</a></span>"
      ],
      "id": "9ade83e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a180beb"
      },
      "outputs": [],
      "source": [
        "class ArcMarginProduct(nn.Module):\n",
        "    r\"\"\"Implement of large margin arc distance: :\n",
        "        Args:\n",
        "            in_features: size of each input sample\n",
        "            out_features: size of each output sample\n",
        "            s: norm of input feature\n",
        "            m: margin\n",
        "            cos(theta + m)\n",
        "        \"\"\"\n",
        "    def __init__(self, in_features, out_features, accelerator,s=30.0, \n",
        "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
        "        super(ArcMarginProduct, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps  # label smoothing\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "        self.accelerator = accelerator\n",
        "\n",
        "    def forward(self, input, label):\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
        "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
        "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        # --------------------------- convert label to one-hot ---------------------\n",
        "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
        "        one_hot = torch.zeros(cosine.size(), device=self.accelerator.device)\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
        "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "\n",
        "        return output"
      ],
      "id": "1a180beb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d00280b1"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Model</h1></span>"
      ],
      "id": "d00280b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "046180c0"
      },
      "outputs": [],
      "source": [
        "class HappyWhaleModel(nn.Module):\n",
        "    def __init__(self, model_name, accelerator,pretrained=True):\n",
        "        super(HappyWhaleModel, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        in_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Identity()\n",
        "        self.model.global_pool = nn.Identity()\n",
        "        self.pooling = GeM()\n",
        "        self.drop = nn.Dropout(p=0.2, inplace=False)\n",
        "        self.fc = nn.Linear(in_features,512)\n",
        "        self.arc = ArcMarginProduct(512, \n",
        "                           CONFIG[\"num_classes\"],\n",
        "                            accelerator,\n",
        "                           s=CONFIG[\"s\"], \n",
        "                           m=CONFIG[\"m\"], \n",
        "                           easy_margin=CONFIG[\"ls_eps\"], \n",
        "                           ls_eps=CONFIG[\"ls_eps\"])\n",
        "    def forward(self, images, labels):\n",
        "        features = self.model(images)\n",
        "        pooled_features = self.pooling(features).flatten(1)\n",
        "        pooled_drop = self.drop(pooled_features)\n",
        "        emb = self.fc(pooled_drop)\n",
        "        output = self.arc(emb,labels)\n",
        "        return output,emb\n"
      ],
      "id": "046180c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d9f236f"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h1></span>"
      ],
      "id": "1d9f236f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f21a2952"
      },
      "outputs": [],
      "source": [
        "def criterion(outputs, labels):\n",
        "    return nn.CrossEntropyLoss()(outputs, labels)"
      ],
      "id": "f21a2952"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eb206fc"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h1></span>"
      ],
      "id": "2eb206fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b479ae1"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, accelerator, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for step, data in enumerate(dataloader):\n",
        "        images = data['image']\n",
        "        labels = data['label']\n",
        "        \n",
        "        batch_size = images.size(0)\n",
        "        \n",
        "        outputs, emb = model(images, labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss = loss / CONFIG['n_accumulate']\n",
        "       \n",
        "        accelerator.backward(loss)\n",
        "    \n",
        "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
        "            optimizer.step()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "                \n",
        "        \n",
        "        if step % CONFIG['log_freq'] == 0:\n",
        "            running_loss += (loss.item() * batch_size)\n",
        "            dataset_size += batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        \n",
        "        del images, labels, batch_size, outputs, emb, loss\n",
        "        gc.collect()\n",
        "        \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ],
      "id": "1b479ae1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6379e683"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1></span>"
      ],
      "id": "6379e683"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a181de1a"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model,optimizer, dataloader, accelerator, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for step, data in enumerate(dataloader):        \n",
        "        images = data['image']\n",
        "        labels = data['label']\n",
        "        \n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        outputs, emb = model(images, labels)\n",
        "        \n",
        "        all_outputs = accelerator.gather(outputs)\n",
        "        all_labels = accelerator.gather(labels)\n",
        "        loss = criterion(all_outputs, all_labels)\n",
        "        \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        del images, labels, batch_size, outputs, emb, all_outputs, all_labels, loss\n",
        "        gc.collect()\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss"
      ],
      "id": "a181de1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6f82412"
      },
      "source": [
        "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h1></span>"
      ],
      "id": "a6f82412"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db043394"
      },
      "outputs": [],
      "source": [
        "def run_training(num_epochs):\n",
        "    accelerator = Accelerator()\n",
        "    \n",
        "    model = HappyWhaleModel(CONFIG['model_name'], accelerator)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n",
        "                       weight_decay=CONFIG['weight_decay'])\n",
        "    \n",
        "    train_loader, valid_loader = prepare_loaders(df, fold=CONFIG['fold_to_run'])\n",
        "    \n",
        "    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader)\n",
        "    valid_loader = accelerator.prepare(valid_loader)\n",
        "    \n",
        "    scheduler = fetch_scheduler(optimizer, train_loader)\n",
        "    \n",
        "#     run = wandb.init(project='happywhale', \n",
        "#                  config=CONFIG,\n",
        "#                  job_type='Train',\n",
        "#                  tags=['arcface', 'gem-pooling', 'effnet-b4', '768'],\n",
        "#                  anonymous='must',\n",
        "#                 group='DDP')\n",
        "\n",
        "#    # To automatically log gradients\n",
        "#    wandb.watch(model, log_freq=100)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "    \n",
        "    start = time.time()\n",
        "    best_epoch_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1): \n",
        "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           accelerator=accelerator, epoch=epoch)\n",
        "        \n",
        "        val_epoch_loss = valid_one_epoch(model,optimizer, valid_loader, accelerator=accelerator, \n",
        "                                         epoch=epoch)\n",
        "        \n",
        "        \n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "\n",
        " #       # Log the metrics\n",
        " #       wandb.log({\"Train Loss\": train_epoch_loss})\n",
        " #       wandb.log({\"Valid Loss\": val_epoch_loss})\n",
        " #       wandb.log({\"LR\": optimizer.param_groups[0]['lr']})\n",
        "            \n",
        "        # save model\n",
        "        accelerator.print(f\"{b_}Validation Loss: {val_epoch_loss}\")\n",
        "        best_epoch_loss = val_epoch_loss\n",
        "#                 run.summary[\"Best Loss\"] = best_epoch_loss\n",
        "        PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n",
        "        accelerator.wait_for_everyone()\n",
        "        unwrapped_model = accelerator.unwrap_model(model)\n",
        "        accelerator.save(unwrapped_model.state_dict(), PATH)\n",
        "        # Save a model file from the current directory\n",
        "        accelerator.print(f\"Model Saved{sr_}\")\n",
        "        \n",
        "        del train_epoch_loss, val_epoch_loss\n",
        "        gc.collect()\n",
        "            \n",
        "        accelerator.print()\n",
        "    \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    accelerator.print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    accelerator.print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
        "#     run.finish()"
      ],
      "id": "db043394"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08f53240"
      },
      "outputs": [],
      "source": [
        "def fetch_scheduler(optimizer, train_loader):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
        "                                                   eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
        "                                                             eta_min=CONFIG['min_lr'])\n",
        "                \n",
        "    elif CONFIG['scheduler'] == 'OneCycleLR':\n",
        "        scheduler = lr_scheduler.OneCycleLR(optimizer,max_lr =CONFIG['learning_rate'],total_steps = CONFIG['epochs'] * len(train_loader))\n",
        "        \n",
        "    elif CONFIG['scheduler'] == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler"
      ],
      "id": "08f53240"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e680b3c8"
      },
      "outputs": [],
      "source": [
        "def prepare_loaders(df, fold):\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"])\n",
        "    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
        "                              num_workers=1, shuffle=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
        "                              num_workers=1, shuffle=False)\n",
        "    \n",
        "    return train_loader, valid_loader"
      ],
      "id": "e680b3c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31b1e58e"
      },
      "source": [
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>"
      ],
      "id": "31b1e58e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "390f5279"
      },
      "outputs": [],
      "source": [
        "def launch():\n",
        "    #run_training(num_epochs=CONFIG['epochs'])\n",
        "    run_training(num_epochs=CONFIG['epochs'])\n",
        "    \n",
        "notebook_launcher(launch)"
      ],
      "id": "390f5279"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wv2v2Y3NrOF"
      },
      "outputs": [],
      "source": [
        "!cp /content/*.bin /content/mydrive/MyDrive/kaggle/pytorch_arcface_bin_pkl/"
      ],
      "id": "9wv2v2Y3NrOF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF0PEeJtLvD-"
      },
      "outputs": [],
      "source": [
        "!cp /content/*.pkl /content/mydrive/MyDrive/kaggle/pytorch_arcface_bin_pkl/"
      ],
      "id": "BF0PEeJtLvD-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEwchhv5LvLA"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "zEwchhv5LvLA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baaf8ade"
      },
      "source": [
        "# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualizations</h1>\n",
        "\n",
        "<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https://wandb.ai/dchanda/HappyWhale/runs/3j25um1k\">View the Complete Dashboard Here ⮕</a></span>"
      ],
      "id": "baaf8ade"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eeb0bd7"
      },
      "source": [
        "![](https://i.imgur.com/zD3rD0W.jpg)"
      ],
      "id": "0eeb0bd7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70118c85"
      },
      "source": [
        "![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)"
      ],
      "id": "70118c85"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "colab pytorch-arcface-gempooling-tpu-train-b6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 374.081758,
      "end_time": "2022-02-25T04:32:01.816711",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-02-25T04:25:47.734953",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}